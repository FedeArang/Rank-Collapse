{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faran\\anaconda3\\envs\\s4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from s4d import S4Model\n",
    "import s4d\n",
    "from s4d import DropoutNd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Dropout broke in PyTorch 1.11\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) == (1, 11):\n",
    "    print(\"WARNING: Dropout is bugged in PyTorch 1.11. Results may be worse.\")\n",
    "    dropout_fn = nn.Dropout\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) >= (1, 12):\n",
    "    dropout_fn = nn.Dropout1d\n",
    "else:\n",
    "    dropout_fn = nn.Dropout2d\n",
    "\n",
    "\n",
    "config = {'d_model': 128, 'n_layers':4, 'dropout':0.1, 'grayscale': False, 'prenorm': False}\n",
    "\n",
    "\n",
    "if config['grayscale']:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=122.6 / 255.0, std=61.0 / 255.0),\n",
    "            transforms.Lambda(lambda x: x.view(1, 1024).t())\n",
    "        ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.Lambda(lambda x: x.view(3, 1024).t())\n",
    "    ])\n",
    "\n",
    "# S4 is trained on sequences with no data augmentation!\n",
    "transform_train = transform_test = transform\n",
    "\n",
    "d_input = 3 if not config['grayscale'] else 1\n",
    "d_output = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = S4Model(\n",
    "    d_input=d_input,\n",
    "    dropout_fn=dropout_fn,\n",
    "    d_output=d_output,\n",
    "    d_model=config['d_model'],\n",
    "    n_layers=config['n_layers'],\n",
    "    dropout=config['dropout'],\n",
    "    prenorm=config['prenorm'],\n",
    "    skip_connection=False,\n",
    "    layer_norm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S4Model(\n",
       "  (encoder): Linear(in_features=3, out_features=128, bias=True)\n",
       "  (s4_layers): ModuleList(\n",
       "    (0): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "    )\n",
       "    (1): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "    )\n",
       "    (2): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "    )\n",
       "    (3): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropouts): ModuleList(\n",
       "    (0): Dropout1d(p=0.1, inplace=False)\n",
       "    (1): Dropout1d(p=0.1, inplace=False)\n",
       "    (2): Dropout1d(p=0.1, inplace=False)\n",
       "    (3): Dropout1d(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = torchvision.datasets.CIFAR10(root='./data/cifar/', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "batch = (next(iter(data_loader)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, all_hidden_states = model(batch)\n",
    "\n",
    "data = (output, all_hidden_states)\n",
    "torch.save(data, 'S4_Skip=False_Norm=False.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_residual(ratios, aggregate=\"all\", c=\"C0\", ax=None, **kwargs):\n",
    "    num_layers, num_samples = ratios.shape[:2]\n",
    "\n",
    "    if aggregate == \"all\":\n",
    "        for sample_idx in range(num_samples):\n",
    "            ax.plot(np.arange(num_layers), ratios[:, sample_idx],\n",
    "                    c=c, alpha=.1, **kwargs)# ax=ax)\n",
    "\n",
    "    mean_value = ratios.mean(axis=-1)\n",
    "    std_value = ratios.std(axis=-1)\n",
    "\n",
    "    ax.plot(np.arange(num_layers), mean_value,\n",
    "                c=c, **kwargs)#, ax=ax)\n",
    "\n",
    "    if aggregate == \"std\":\n",
    "        ax.fill_between(np.arange(num_layers), mean_value - std_value, mean_value + std_value,\n",
    "                         color=c, alpha=.2)\n",
    "\n",
    "    plt.xlabel(f\"layer index\")\n",
    "    plt.ylim([0 - 0.01, 1 + 0.01])\n",
    "    plt.grid(alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import random\n",
    "\n",
    "def compute_low_rank(x, k=1):\n",
    "    U, s, Vh = jax.vmap(jnp.linalg.svd)(x)\n",
    "    return jnp.einsum(\"ij,j,jk->ik\", U[:, :k], s[:k], Vh[:k ,:])\n",
    "\n",
    "def l1_matrix_norm(x):\n",
    "    return x.abs().sum(axis=-2 % x.ndim).max(axis=-1).values\n",
    "\n",
    "def linf_matrix_norm(x):\n",
    "    return l1_matrix_norm(x.transpose(-2, -1))\n",
    "\n",
    "def composite_norm(x):\n",
    "    return torch.sqrt(l1_matrix_norm(x) * linf_matrix_norm(x))\n",
    "\n",
    "all_norms = {\n",
    "    \"l1\": l1_matrix_norm,\n",
    "    \"l2\": lambda r: torch.norm(r, p=2, dim=(-2, -1)),\n",
    "    \"l_inf\": linf_matrix_norm,\n",
    "    \"l1 * l_inf\": composite_norm,\n",
    "}\n",
    "\n",
    "all_norms_names = list(all_norms.keys())\n",
    "\n",
    "def sample_path(depth, num_layers, num_heads):\n",
    "    selected_layers = sorted(random.sample(list(range(num_layers)), depth))\n",
    "    selected_heads = random.choices(list(range(num_heads)), k=depth)\n",
    "    return selected_layers, selected_heads\n",
    "\n",
    "def sample_P_matrix(attentions, depth: int):\n",
    "    num_layers, num_samples, num_heads, t, _ = attentions.shape\n",
    "    selected_layers, selected_heads = sample_path(depth, num_layers, num_heads)\n",
    "    sample_idx = random.choice(list(range(num_samples)))\n",
    "    P = torch.eye(t)\n",
    "    for layer, head in zip(selected_layers, selected_heads):\n",
    "        P = P @ attentions[layer, sample_idx, head]\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS4_Skip=False_Norm=False.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m all_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\n\u001b[0;32m     18\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(all_hidden_states)\n\u001b[0;32m     19\u001b[0m residuals \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m-\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'detach'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"text.usetex\"] = False\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for skip in [True, False]:\n",
    "    for layer_norm in [True, False]:\n",
    "\n",
    "        if skip==True and layer_norm==True:\n",
    "            data = torch.load(\"S4_Skip=True_Norm=True.pt\")\n",
    "        elif skip==True and layer_norm==False:\n",
    "            data = torch.load(\"S4_Skip=True_Norm=False.pt\")\n",
    "        elif skip==False and layer_norm==True:\n",
    "            data = torch.load(\"S4_Skip=False_Norm=True.pt\")\n",
    "        else:\n",
    "            data = torch.load(\"S4_Skip=False_Norm=False.pt\")\n",
    "        \n",
    "        all_hidden_states = data[1]\n",
    "        hidden_states = torch.stack(all_hidden_states)\n",
    "        residuals = hidden_states - hidden_states.mean(dim=-2, keepdim=True)\n",
    "\n",
    "        norm_fn = all_norms[\"l1 * l_inf\"]\n",
    "        ratio = norm_fn(residuals) / norm_fn(hidden_states)\n",
    "\n",
    "        num_layers, num_samples = ratio.shape[:2]\n",
    "\n",
    "        mean_value = ratio.mean(axis=-1)\n",
    "        std_value = ratio.std(axis=-1)\n",
    "\n",
    "        if skip==True and layer_norm==True:\n",
    "            plt.fill_between(np.arange(num_layers), mean_value - std_value, mean_value + std_value,\n",
    "                            color=\"C0\", alpha=0.2)\n",
    "            plt.plot(np.arange(num_layers), mean_value, color=\"C0\", label=\"Skip=True, Norm=True\")\n",
    "        elif skip==True and layer_norm==False:\n",
    "            plt.fill_between(np.arange(num_layers), mean_value - std_value, mean_value + std_value,\n",
    "                            color=\"C1\", alpha=0.2)\n",
    "            plt.plot(np.arange(num_layers), mean_value, color=\"C1\", label=\"Skip=True, Norm=False\")\n",
    "        elif skip==False and layer_norm==True:\n",
    "            plt.fill_between(np.arange(num_layers), mean_value - std_value, mean_value + std_value,\n",
    "                            color=\"C2\", alpha=0.2)\n",
    "            plt.plot(np.arange(num_layers), mean_value, color=\"C2\", label=\"Skip=False, Norm=True\")\n",
    "        else:\n",
    "            plt.fill_between(np.arange(num_layers), mean_value - std_value, mean_value + std_value,\n",
    "                            color=\"C3\", alpha=0.2)\n",
    "            plt.plot(np.arange(num_layers), mean_value, color=\"C3\", label=\"Skip=False, Norm=False\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.title(\"Ratio of Residuals to Hidden States\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-collapse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
